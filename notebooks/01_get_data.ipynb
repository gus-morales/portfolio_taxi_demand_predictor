{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS & CONFIG\n",
    "\n",
    "# utils\n",
    "import requests\n",
    "import sys\n",
    "import os\n",
    "import configparser\n",
    "from watermark import watermark\n",
    "from loguru import logger\n",
    "from pathlib import Path\n",
    "\n",
    "# data science\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# config\n",
    "logger_format = (\n",
    "    \"<green>{time:MMM-D HH:mm:ss.SSS}</green> | \"\n",
    "    \"<level>{level: <8}</level> | \"\n",
    "    \"<level>{message}</level>\"\n",
    ")\n",
    "logger.configure(extra={\"ip\": \"\", \"user\": \"\"})  # Default values\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, format=logger_format)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "\n",
    "def download_one_file_of_raw_data_from_nyc_gov_website(dir_path:str, year:int, month:int) -> str:\n",
    "    \"\"\"\"\"\"\n",
    "    url_string = f'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{year}-{month:02d}.parquet'\n",
    "    response = requests.get(url_string)\n",
    "\n",
    "    if response.status_code==200:\n",
    "        logger.info(f\"Writing rides_{year}-{month:02d}.parquet\")\n",
    "        path = f'{dir_path}/rides_{year}-{month:02d}.parquet'\n",
    "        open(path, 'wb').write(response.content)\n",
    "        return path\n",
    "    \n",
    "    else:\n",
    "        raise Exception(f'{url_string} is not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Gustavo Morales\n",
      "\n",
      "Last updated: 2023-08-21\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.4\n",
      "IPython version      : 8.14.0\n",
      "\n",
      "pandas: 2.0.3\n",
      "numpy : 1.25.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# WATERMARK\n",
    "wmrk_dict = {\n",
    "    'author':'Gustavo Morales',\n",
    "    'current_date':True,\n",
    "    'updated':True,\n",
    "    'python':True,\n",
    "    'packages':'pandas,numpy',\n",
    "}\n",
    "\n",
    "print(watermark(**wmrk_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hardcoded notebook parameters\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.cfg')\n",
    "\n",
    "years = [2022]\n",
    "months = list(np.arange(1,13))\n",
    "raw_data_dir_path = config['PATHS']['raw_data_dir_path']\n",
    "validated_raw_data_file_path = config['PATHS']['validated_raw_data_file_path']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fetching the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mAug-21 01:12:45.554\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m12 parquet files already present, fetch skipped.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rides_2022-01.parquet\n",
      "rides_2022-02.parquet\n",
      "rides_2022-03.parquet\n",
      "rides_2022-04.parquet\n",
      "rides_2022-05.parquet\n",
      "rides_2022-06.parquet\n",
      "rides_2022-07.parquet\n",
      "rides_2022-08.parquet\n",
      "rides_2022-09.parquet\n",
      "rides_2022-10.parquet\n",
      "rides_2022-11.parquet\n",
      "rides_2022-12.parquet\n"
     ]
    }
   ],
   "source": [
    "# fetch and write parquet data files; one per year-month\n",
    "total_expected_files = len(months)*len(years)\n",
    "\n",
    "# check if files exist already, otherwise download them to disk\n",
    "number_of_files = len([entry for entry in os.listdir(raw_data_dir_path) if os.path.isfile(os.path.join(raw_data_dir_path, entry))])\n",
    "if number_of_files==total_expected_files:\n",
    "    logger.success(f\"{number_of_files} parquet files already present, fetch skipped.\")\n",
    "    os.system(f\"cd {raw_data_dir_path}; ls -h\")\n",
    "else:\n",
    "    logger.info(f\"Fetching files...\")\n",
    "\n",
    "    for y in years:\n",
    "        for m in months:\n",
    "            download_one_file_of_raw_data_from_nyc_gov_website(raw_data_dir_path,y,m)\n",
    "\n",
    "    logger.success(\"âœ“\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate parquet tables into a pandas-df\n",
    "# this could be done faster; check https://jpweytjens.be/read-multiple-files-with-pandas-fast/\n",
    "raw_data_dir = Path(raw_data_dir_path)\n",
    "full_df = pd.concat(\n",
    "    pd.read_parquet(parquet_file)\n",
    "    for parquet_file in raw_data_dir.glob('*.parquet')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 39656098 entries, 0 to 3183766\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   VendorID               int64         \n",
      " 1   tpep_pickup_datetime   datetime64[ns]\n",
      " 2   tpep_dropoff_datetime  datetime64[ns]\n",
      " 3   passenger_count        float64       \n",
      " 4   trip_distance          float64       \n",
      " 5   RatecodeID             float64       \n",
      " 6   store_and_fwd_flag     object        \n",
      " 7   PULocationID           int64         \n",
      " 8   DOLocationID           int64         \n",
      " 9   payment_type           int64         \n",
      " 10  fare_amount            float64       \n",
      " 11  extra                  float64       \n",
      " 12  mta_tax                float64       \n",
      " 13  tip_amount             float64       \n",
      " 14  tolls_amount           float64       \n",
      " 15  improvement_surcharge  float64       \n",
      " 16  total_amount           float64       \n",
      " 17  congestion_surcharge   float64       \n",
      " 18  airport_fee            float64       \n",
      "dtypes: datetime64[ns](2), float64(12), int64(4), object(1)\n",
      "memory usage: 5.9+ GB\n"
     ]
    }
   ],
   "source": [
    "# check full df\n",
    "full_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 39656098 entries, 0 to 3183766\n",
      "Data columns (total 2 columns):\n",
      " #   Column              Dtype         \n",
      "---  ------              -----         \n",
      " 0   pickup_datetime     datetime64[ns]\n",
      " 1   pickup_location_id  int64         \n",
      "dtypes: datetime64[ns](1), int64(1)\n",
      "memory usage: 907.7 MB\n"
     ]
    }
   ],
   "source": [
    "# slice relevant data and check\n",
    "rides_df = full_df.copy()[['tpep_pickup_datetime', 'PULocationID']]\n",
    "\n",
    "rides_df.rename(columns={\n",
    "    'tpep_pickup_datetime': 'pickup_datetime',\n",
    "    'PULocationID': 'pickup_location_id',\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "rides_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                         39656098\n",
       "mean     2022-07-05 04:04:16.211664640\n",
       "min                2001-01-01 00:03:14\n",
       "25%                2022-04-07 21:59:21\n",
       "50%         2022-07-01 06:36:25.500000\n",
       "75%                2022-10-04 20:17:12\n",
       "max                2023-04-18 14:30:05\n",
       "Name: pickup_datetime, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if data spans the correct time window\n",
    "rides_df['pickup_datetime'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                         39655537\n",
       "mean     2022-07-05 06:17:00.079098624\n",
       "min                2022-01-01 00:00:08\n",
       "25%                2022-04-07 22:03:08\n",
       "50%                2022-07-01 06:45:00\n",
       "75%                2022-10-04 20:18:32\n",
       "max                2022-12-31 23:59:59\n",
       "Name: pickup_datetime, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix the time window\n",
    "rides_df = rides_df[rides_df.pickup_datetime >= '2022-01-01']\n",
    "rides_df = rides_df[rides_df.pickup_datetime < '2023-01-01']\n",
    "rides_df['pickup_datetime'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the transformed table to a parquet file for further processing\n",
    "rides_df.to_parquet(validated_raw_data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mAug-21 01:13:09.186\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mNotebook finished.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.success(\"Notebook finished.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "tt {\n",
    "    font-family:\n",
    "    \"MonoLisa\",\n",
    "    \"Courier Prime\",\n",
    "    \"Courier New\",\n",
    "    \"Inconsolata\",\n",
    "    \"Lucida Console\",\n",
    "    \"Menlo\",\n",
    "    \"Monaco\", \n",
    "    monospace;\n",
    "    color: \"black\";\n",
    "    font: 10px;\n",
    "}\n",
    "\n",
    "alert {\n",
    "    display: inline-block;\n",
    "}\n",
    "    \n",
    ".alert-block{\n",
    "    margin: 20px;\n",
    "    width: 92%;\n",
    "    padding: 15px;\n",
    "    border-radius: 4px;\n",
    "    font: 16px Tahoma, Alegreya, Garamond, Times;\n",
    "    font-weight: 400;\n",
    "}\n",
    "\n",
    ".alert-info {\n",
    "    color: #0399A9;\n",
    "    background: #B2EBF3;\n",
    "    border: 2px solid #4FD1E1;\n",
    "}\n",
    "\n",
    ".alert-warning {\n",
    "    color: #F67C00;\n",
    "    background: #FFE0B2;\n",
    "    border: 2px solid #FFC165;\n",
    "}\n",
    "\n",
    ".alert-danger {\n",
    "    color: #C4453E;\n",
    "    background: #F7CFD3;\n",
    "    border: 2px solid #E29C9B;\n",
    "}\n",
    "\n",
    ".alert-success {\n",
    "    color: #388E3C;\n",
    "    background: #C8E6C9;\n",
    "    border: 2px solid #81C784;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"> </div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
