{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS & CONFIG\n",
    "\n",
    "# utils\n",
    "from watermark import watermark\n",
    "from loguru import logger\n",
    "import sys\n",
    "import configparser\n",
    "from tqdm import tqdm\n",
    "\n",
    "# data science\n",
    "import pandas as pd\n",
    "\n",
    "# config\n",
    "logger_format = (\n",
    "    \"<green>{time:MMM-D HH:mm:ss.SSS}</green> | \"\n",
    "    \"<level>{level: <8}</level> | \"\n",
    "    \"<level>{message}</level>\"\n",
    ")\n",
    "logger.configure(extra={\"ip\": \"\", \"user\": \"\"})\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, format=logger_format)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "\n",
    "def get_cutoff_indices(\n",
    "    data: pd.DataFrame,\n",
    "    n_rows: int,\n",
    "    step_size: int\n",
    "    ) -> list:\n",
    "        \"\"\"\n",
    "        Slices and slides the input dataframe into a list of cutoff indices to prepare the data for training.\n",
    "        \"\"\"\n",
    "        stop_position = len(data) - 1\n",
    "        \n",
    "        # Start the first sub-sequence at index position 0\n",
    "        subseq_first_idx = 0\n",
    "        subseq_mid_idx = n_rows\n",
    "        subseq_last_idx = n_rows + 1\n",
    "        indices = []\n",
    "        \n",
    "        while subseq_last_idx <= stop_position:\n",
    "            indices.append((subseq_first_idx, subseq_mid_idx, subseq_last_idx))\n",
    "            \n",
    "            subseq_first_idx += step_size\n",
    "            subseq_mid_idx += step_size\n",
    "            subseq_last_idx += step_size\n",
    "\n",
    "        return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Gustavo Morales\n",
      "\n",
      "Last updated: 2023-08-21\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.4\n",
      "IPython version      : 8.14.0\n",
      "\n",
      "pandas: 2.0.3\n",
      "numpy : 1.25.0\n",
      "plotly: 5.15.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# WATERMARK\n",
    "wmrk_dict = {\n",
    "    'author':'Gustavo Morales',\n",
    "    'current_date':True,\n",
    "    'updated':True,\n",
    "    'python':True,\n",
    "    'packages':'pandas,numpy,plotly',\n",
    "}\n",
    "\n",
    "print(watermark(**wmrk_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hardcoded notebook parameters\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.cfg')\n",
    "\n",
    "complete_data_file_path = config['PATHS']['complete_data_file_path']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, the idea is to use the TS data created in notebook `02` to generate tabular data. After feature engineering, this tabular data will be ready to train supervised models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2295120 entries, 0 to 2295119\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Dtype         \n",
      "---  ------              -----         \n",
      " 0   pickup_hour         datetime64[ns]\n",
      " 1   total_rides         int64         \n",
      " 2   pickup_location_id  int64         \n",
      "dtypes: datetime64[ns](1), int64(2)\n",
      "memory usage: 52.5 MB\n"
     ]
    }
   ],
   "source": [
    "rides_df = pd.read_parquet(complete_data_file_path)\n",
    "rides_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want to focus on one location, Central Park."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>total_rides</th>\n",
       "      <th>pickup_location_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>97</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "      <td>60</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 02:00:00</td>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "      <td>8</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 04:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-01-01 05:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-01-01 06:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-01-01 07:00:00</td>\n",
       "      <td>10</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-01-01 08:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-01-01 09:00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pickup_hour  total_rides  pickup_location_id\n",
       "0 2022-01-01 00:00:00           97                  43\n",
       "1 2022-01-01 01:00:00           60                  43\n",
       "2 2022-01-01 02:00:00           22                  43\n",
       "3 2022-01-01 03:00:00            8                  43\n",
       "4 2022-01-01 04:00:00            6                  43\n",
       "5 2022-01-01 05:00:00            5                  43\n",
       "6 2022-01-01 06:00:00            3                  43\n",
       "7 2022-01-01 07:00:00           10                  43\n",
       "8 2022-01-01 08:00:00            7                  43\n",
       "9 2022-01-01 09:00:00           19                  43"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slicing the main df accordingly\n",
    "rides_cp_df = rides_df.loc[rides_df.pickup_location_id==43, :].reset_index(drop=True)\n",
    "rides_cp_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8760"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rides_cp_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can take the first 24 rows of data (so, one day worth of hourly data) and get their respective cutoff indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 24, 25), (1, 25, 26), (2, 26, 27), (3, 27, 28), (4, 28, 29)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take the first day of data and show first 5 sets of cutoff indices\n",
    "n_rows = 24\n",
    "step_size = 1\n",
    "\n",
    "indices = get_cutoff_indices(\n",
    "    rides_cp_df,\n",
    "    n_rows,\n",
    "    step_size\n",
    ")\n",
    "indices[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
